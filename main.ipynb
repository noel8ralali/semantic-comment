{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils.DataProcessing as DP\n",
    "import utils.LSTM as lstm\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('data/model/lstm_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_filename = \"data/json/pos.json\"\n",
    "neg_filename = \"data/json/neg.json\"\n",
    "pos_test_filename = \"data/json/pos_test.json\"\n",
    "neg_test_filename = \"data/json/neg_test.json\"\n",
    "stopword_filename = \"data/json/stopword.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_file = open(pos_filename)\n",
    "pos_data = json.load(pos_file)\n",
    "\n",
    "neg_file = open(neg_filename)\n",
    "neg_data = json.load(neg_file)\n",
    "dataset = pos_data + neg_data\n",
    "train_dataset = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_file = open(pos_test_filename)\n",
    "pos_test_data = json.load(pos_test_file)\n",
    "\n",
    "neg_test_file = open(neg_test_filename)\n",
    "neg_test_data = json.load(neg_test_file)\n",
    "\n",
    "test_dataset = pos_test_data + neg_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "68\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataset))\n",
    "print(len(pos_test_data))\n",
    "print(len(neg_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_file = open(stopword_filename)\n",
    "stopword = json.load(stopword_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_prev_corpus = True\n",
    "if use_prev_corpus:\n",
    "    corpus_file = open(\"data/dicts/corpus.pickle\", 'rb')\n",
    "    corpus = pickle.load(corpus_file)\n",
    "else:\n",
    "    corpus = DP.Corpus(data=dataset, \n",
    "                       dictionary_word=[], \n",
    "                       stopwords=stopword)\n",
    "    corpus_file = open(\"data/dicts/corpus.pickle\", 'wb')\n",
    "    pickle.dump(corpus, corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 2000\n",
    "#embedding_dim = int(len(corpus.dictionary) ** 0.25)\n",
    "embedding_dim = 15\n",
    "hidden_dim = 5\n",
    "sent_size = 15\n",
    "nlabel = 2\n",
    "lr = 0.05\n",
    "use_gpu = torch.cuda.is_available()\n",
    "corpus_size = len(corpus.dictionary.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21172"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51037\n",
      "51037\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm.LSTMClassifier(embedding_dim, \n",
    "                            hidden_dim,\n",
    "                            corpus_size, \n",
    "                            nlabel, \n",
    "                            batch_size)\n",
    "if use_gpu: model = model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration: 1/1700\n",
      "accuracy: 0.47\n",
      "loss: 0.71\n",
      "iterration: 2/1700\n",
      "accuracy: 0.48\n",
      "loss: 0.71\n",
      "iterration: 3/1700\n",
      "accuracy: 0.48\n",
      "loss: 0.70\n",
      "iterration: 4/1700\n",
      "accuracy: 0.46\n",
      "loss: 0.70\n",
      "iterration: 5/1700\n",
      "accuracy: 0.42\n",
      "loss: 0.70\n",
      "iterration: 6/1700\n",
      "accuracy: 0.54\n",
      "loss: 0.69\n",
      "iterration: 7/1700\n",
      "accuracy: 0.52\n",
      "loss: 0.69\n",
      "iterration: 8/1700\n",
      "accuracy: 0.55\n",
      "loss: 0.69\n",
      "iterration: 9/1700\n",
      "accuracy: 0.54\n",
      "loss: 0.69\n",
      "iterration: 10/1700\n",
      "accuracy: 0.53\n",
      "loss: 0.69\n",
      "iterration: 11/1700\n",
      "accuracy: 0.55\n",
      "loss: 0.69\n",
      "iterration: 12/1700\n",
      "accuracy: 0.57\n",
      "loss: 0.68\n",
      "iterration: 13/1700\n",
      "accuracy: 0.56\n",
      "loss: 0.68\n",
      "iterration: 14/1700\n",
      "accuracy: 0.57\n",
      "loss: 0.68\n",
      "iterration: 18/1700\n",
      "accuracy: 0.56\n",
      "loss: 0.69\n",
      "iterration: 19/1700\n",
      "accuracy: 0.56\n",
      "loss: 0.68\n",
      "iterration: 20/1700\n",
      "accuracy: 0.56\n",
      "loss: 0.68\n",
      "iterration: 21/1700\n",
      "accuracy: 0.57\n",
      "loss: 0.68\n",
      "iterration: 22/1700\n",
      "accuracy: 0.58\n",
      "loss: 0.68\n",
      "iterration: 23/1700\n",
      "accuracy: 0.57\n",
      "loss: 0.68\n",
      "iterration: 24/1700\n",
      "accuracy: 0.59\n",
      "loss: 0.68\n",
      "iterration: 25/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.68\n",
      "iterration: 26/1700\n",
      "accuracy: 0.59\n",
      "loss: 0.68\n",
      "iterration: 27/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.67\n",
      "iterration: 28/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.67\n",
      "iterration: 29/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.67\n",
      "iterration: 30/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.67\n",
      "iterration: 31/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.67\n",
      "iterration: 35/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.67\n",
      "iterration: 36/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.67\n",
      "iterration: 37/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.67\n",
      "iterration: 38/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.67\n",
      "iterration: 39/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.67\n",
      "iterration: 40/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.67\n",
      "iterration: 41/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.67\n",
      "iterration: 42/1700\n",
      "accuracy: 0.59\n",
      "loss: 0.67\n",
      "iterration: 43/1700\n",
      "accuracy: 0.58\n",
      "loss: 0.67\n",
      "iterration: 44/1700\n",
      "accuracy: 0.59\n",
      "loss: 0.67\n",
      "iterration: 45/1700\n",
      "accuracy: 0.59\n",
      "loss: 0.67\n",
      "iterration: 46/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.66\n",
      "iterration: 47/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.66\n",
      "iterration: 48/1700\n",
      "accuracy: 0.59\n",
      "loss: 0.67\n",
      "iterration: 52/1700\n",
      "accuracy: 0.59\n",
      "loss: 0.67\n",
      "iterration: 53/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.66\n",
      "iterration: 54/1700\n",
      "accuracy: 0.58\n",
      "loss: 0.67\n",
      "iterration: 55/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.66\n",
      "iterration: 56/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.66\n",
      "iterration: 57/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.67\n",
      "iterration: 58/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.66\n",
      "iterration: 59/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.66\n",
      "iterration: 60/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.66\n",
      "iterration: 61/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.66\n",
      "iterration: 62/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.66\n",
      "iterration: 63/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.66\n",
      "iterration: 64/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.66\n",
      "iterration: 65/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.66\n",
      "iterration: 69/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.66\n",
      "iterration: 70/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 71/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.66\n",
      "iterration: 72/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.65\n",
      "iterration: 73/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.66\n",
      "iterration: 74/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.66\n",
      "iterration: 75/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.65\n",
      "iterration: 76/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 77/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.65\n",
      "iterration: 78/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 79/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.66\n",
      "iterration: 80/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 81/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.64\n",
      "iterration: 82/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.65\n",
      "iterration: 86/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.64\n",
      "iterration: 87/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.65\n",
      "iterration: 88/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.64\n",
      "iterration: 89/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 90/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 91/1700\n",
      "accuracy: 0.65\n",
      "loss: 0.64\n",
      "iterration: 92/1700\n",
      "accuracy: 0.68\n",
      "loss: 0.63\n",
      "iterration: 93/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.65\n",
      "iterration: 94/1700\n",
      "accuracy: 0.65\n",
      "loss: 0.63\n",
      "iterration: 95/1700\n",
      "accuracy: 0.65\n",
      "loss: 0.63\n",
      "iterration: 96/1700\n",
      "accuracy: 0.65\n",
      "loss: 0.63\n",
      "iterration: 97/1700\n",
      "accuracy: 0.67\n",
      "loss: 0.63\n",
      "iterration: 98/1700\n",
      "accuracy: 0.69\n",
      "loss: 0.62\n",
      "iterration: 99/1700\n",
      "accuracy: 0.68\n",
      "loss: 0.62\n",
      "iterration: 103/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.64\n",
      "iterration: 104/1700\n",
      "accuracy: 0.69\n",
      "loss: 0.62\n",
      "iterration: 105/1700\n",
      "accuracy: 0.67\n",
      "loss: 0.63\n",
      "iterration: 106/1700\n",
      "accuracy: 0.68\n",
      "loss: 0.62\n",
      "iterration: 107/1700\n",
      "accuracy: 0.67\n",
      "loss: 0.61\n",
      "iterration: 108/1700\n",
      "accuracy: 0.69\n",
      "loss: 0.61\n",
      "iterration: 109/1700\n",
      "accuracy: 0.69\n",
      "loss: 0.62\n",
      "iterration: 110/1700\n",
      "accuracy: 0.68\n",
      "loss: 0.61\n",
      "iterration: 111/1700\n",
      "accuracy: 0.67\n",
      "loss: 0.62\n",
      "iterration: 112/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.58\n",
      "iterration: 113/1700\n",
      "accuracy: 0.70\n",
      "loss: 0.58\n",
      "iterration: 114/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.59\n",
      "iterration: 115/1700\n",
      "accuracy: 0.65\n",
      "loss: 0.64\n",
      "iterration: 116/1700\n",
      "accuracy: 0.68\n",
      "loss: 0.62\n",
      "iterration: 120/1700\n",
      "accuracy: 0.52\n",
      "loss: 0.72\n",
      "iterration: 121/1700\n",
      "accuracy: 0.69\n",
      "loss: 0.61\n",
      "iterration: 122/1700\n",
      "accuracy: 0.66\n",
      "loss: 0.63\n",
      "iterration: 123/1700\n",
      "accuracy: 0.70\n",
      "loss: 0.59\n",
      "iterration: 124/1700\n",
      "accuracy: 0.58\n",
      "loss: 0.67\n",
      "iterration: 125/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.67\n",
      "iterration: 126/1700\n",
      "accuracy: 0.60\n",
      "loss: 0.70\n",
      "iterration: 127/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.68\n",
      "iterration: 128/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.67\n",
      "iterration: 129/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.64\n",
      "iterration: 130/1700\n",
      "accuracy: 0.66\n",
      "loss: 0.62\n",
      "iterration: 131/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.60\n",
      "iterration: 132/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.67\n",
      "iterration: 133/1700\n",
      "accuracy: 0.69\n",
      "loss: 0.63\n",
      "iterration: 137/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.64\n",
      "iterration: 138/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.64\n",
      "iterration: 139/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.64\n",
      "iterration: 140/1700\n",
      "accuracy: 0.61\n",
      "loss: 0.65\n",
      "iterration: 141/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.64\n",
      "iterration: 142/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.64\n",
      "iterration: 143/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.64\n",
      "iterration: 144/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 145/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.64\n",
      "iterration: 146/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.65\n",
      "iterration: 147/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.64\n",
      "iterration: 148/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 149/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 150/1700\n",
      "accuracy: 0.65\n",
      "loss: 0.63\n",
      "iterration: 154/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.64\n",
      "iterration: 155/1700\n",
      "accuracy: 0.62\n",
      "loss: 0.65\n",
      "iterration: 156/1700\n",
      "accuracy: 0.63\n",
      "loss: 0.64\n",
      "iterration: 157/1700\n",
      "accuracy: 0.65\n",
      "loss: 0.63\n",
      "iterration: 158/1700\n",
      "accuracy: 0.64\n",
      "loss: 0.63\n",
      "iterration: 159/1700\n",
      "accuracy: 0.66\n",
      "loss: 0.63\n",
      "iterration: 160/1700\n",
      "accuracy: 0.66\n",
      "loss: 0.63\n",
      "iterration: 161/1700\n",
      "accuracy: 0.67\n",
      "loss: 0.62\n",
      "iterration: 162/1700\n",
      "accuracy: 0.68\n",
      "loss: 0.62\n",
      "iterration: 163/1700\n",
      "accuracy: 0.65\n",
      "loss: 0.63\n",
      "iterration: 164/1700\n",
      "accuracy: 0.69\n",
      "loss: 0.60\n",
      "iterration: 165/1700\n",
      "accuracy: 0.70\n",
      "loss: 0.61\n",
      "iterration: 166/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.60\n",
      "iterration: 167/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.59\n",
      "iterration: 171/1700\n",
      "accuracy: 0.69\n",
      "loss: 0.61\n",
      "iterration: 172/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.60\n",
      "iterration: 173/1700\n",
      "accuracy: 0.69\n",
      "loss: 0.60\n",
      "iterration: 174/1700\n",
      "accuracy: 0.70\n",
      "loss: 0.59\n",
      "iterration: 175/1700\n",
      "accuracy: 0.70\n",
      "loss: 0.58\n",
      "iterration: 176/1700\n",
      "accuracy: 0.70\n",
      "loss: 0.58\n",
      "iterration: 177/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.59\n",
      "iterration: 178/1700\n",
      "accuracy: 0.68\n",
      "loss: 0.60\n",
      "iterration: 179/1700\n",
      "accuracy: 0.70\n",
      "loss: 0.57\n",
      "iterration: 180/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.57\n",
      "iterration: 181/1700\n",
      "accuracy: 0.72\n",
      "loss: 0.57\n",
      "iterration: 182/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.58\n",
      "iterration: 183/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.58\n",
      "iterration: 184/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.57\n",
      "iterration: 188/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.56\n",
      "iterration: 189/1700\n",
      "accuracy: 0.70\n",
      "loss: 0.58\n",
      "iterration: 190/1700\n",
      "accuracy: 0.70\n",
      "loss: 0.58\n",
      "iterration: 191/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.57\n",
      "iterration: 192/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.57\n",
      "iterration: 193/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.56\n",
      "iterration: 194/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.58\n",
      "iterration: 195/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.55\n",
      "iterration: 196/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.57\n",
      "iterration: 197/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.58\n",
      "iterration: 198/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.56\n",
      "iterration: 199/1700\n",
      "accuracy: 0.72\n",
      "loss: 0.56\n",
      "iterration: 200/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.56\n",
      "iterration: 201/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.55\n",
      "iterration: 205/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.56\n",
      "iterration: 206/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.55\n",
      "iterration: 207/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.54\n",
      "iterration: 208/1700\n",
      "accuracy: 0.72\n",
      "loss: 0.55\n",
      "iterration: 209/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.54\n",
      "iterration: 210/1700\n",
      "accuracy: 0.72\n",
      "loss: 0.57\n",
      "iterration: 211/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.57\n",
      "iterration: 212/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.55\n",
      "iterration: 213/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration: 214/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.54\n",
      "iterration: 215/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.55\n",
      "iterration: 216/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.54\n",
      "iterration: 217/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.54\n",
      "iterration: 218/1700\n",
      "accuracy: 0.71\n",
      "loss: 0.57\n",
      "iterration: 222/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.55\n",
      "iterration: 223/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.54\n",
      "iterration: 224/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.55\n",
      "iterration: 225/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.55\n",
      "iterration: 226/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.55\n",
      "iterration: 227/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.54\n",
      "iterration: 228/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.54\n",
      "iterration: 229/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.54\n",
      "iterration: 230/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.55\n",
      "iterration: 231/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.53\n",
      "iterration: 232/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.53\n",
      "iterration: 233/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.53\n",
      "iterration: 234/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.53\n",
      "iterration: 235/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.52\n",
      "iterration: 239/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.53\n",
      "iterration: 240/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.53\n",
      "iterration: 241/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.52\n",
      "iterration: 242/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.53\n",
      "iterration: 243/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.54\n",
      "iterration: 244/1700\n",
      "accuracy: 0.72\n",
      "loss: 0.55\n",
      "iterration: 245/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.55\n",
      "iterration: 246/1700\n",
      "accuracy: 0.72\n",
      "loss: 0.55\n",
      "iterration: 247/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 248/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.52\n",
      "iterration: 249/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 250/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.52\n",
      "iterration: 251/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.52\n",
      "iterration: 252/1700\n",
      "accuracy: 0.72\n",
      "loss: 0.54\n",
      "iterration: 256/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.53\n",
      "iterration: 257/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.53\n",
      "iterration: 258/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 259/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.52\n",
      "iterration: 260/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.52\n",
      "iterration: 261/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.52\n",
      "iterration: 262/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.53\n",
      "iterration: 263/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.51\n",
      "iterration: 264/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.52\n",
      "iterration: 265/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 266/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.52\n",
      "iterration: 267/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.53\n",
      "iterration: 268/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.52\n",
      "iterration: 269/1700\n",
      "accuracy: 0.73\n",
      "loss: 0.53\n",
      "iterration: 273/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.51\n",
      "iterration: 274/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 275/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.52\n",
      "iterration: 276/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.53\n",
      "iterration: 277/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 278/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.53\n",
      "iterration: 279/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.52\n",
      "iterration: 280/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.51\n",
      "iterration: 281/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 282/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 283/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 284/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 285/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.52\n",
      "iterration: 286/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 290/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.52\n",
      "iterration: 291/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.49\n",
      "iterration: 292/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 293/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.53\n",
      "iterration: 294/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 295/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.50\n",
      "iterration: 296/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 297/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 298/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.49\n",
      "iterration: 299/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.52\n",
      "iterration: 300/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.53\n",
      "iterration: 301/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 302/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.50\n",
      "iterration: 303/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.49\n",
      "iterration: 307/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.50\n",
      "iterration: 308/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 309/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 310/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 311/1700\n",
      "accuracy: 0.75\n",
      "loss: 0.53\n",
      "iterration: 312/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 313/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 314/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 315/1700\n",
      "accuracy: 0.74\n",
      "loss: 0.51\n",
      "iterration: 316/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.50\n",
      "iterration: 317/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 318/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.49\n",
      "iterration: 319/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.50\n",
      "iterration: 320/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 324/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 325/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 326/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 327/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.50\n",
      "iterration: 328/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 329/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.51\n",
      "iterration: 330/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.51\n",
      "iterration: 331/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 332/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.50\n",
      "iterration: 333/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.50\n",
      "iterration: 334/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 335/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 336/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.48\n",
      "iterration: 337/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 341/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.49\n",
      "iterration: 342/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 343/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 344/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 345/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 346/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 347/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 348/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 349/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 350/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 351/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.50\n",
      "iterration: 352/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 353/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.48\n",
      "iterration: 354/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 358/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 359/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 360/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.50\n",
      "iterration: 361/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.48\n",
      "iterration: 362/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.49\n",
      "iterration: 363/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 364/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.49\n",
      "iterration: 365/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 366/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 367/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.49\n",
      "iterration: 368/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 369/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.46\n",
      "iterration: 370/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 371/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 375/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 376/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 377/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 378/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 379/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 380/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 381/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.48\n",
      "iterration: 382/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 383/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.49\n",
      "iterration: 384/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 385/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 386/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 387/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 388/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 392/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 393/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.48\n",
      "iterration: 394/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.49\n",
      "iterration: 395/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 396/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.46\n",
      "iterration: 397/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.46\n",
      "iterration: 398/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 399/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 400/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 401/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 402/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 403/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.49\n",
      "iterration: 404/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.47\n",
      "iterration: 405/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.46\n",
      "iterration: 409/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 410/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.48\n",
      "iterration: 411/1700\n",
      "accuracy: 0.77\n",
      "loss: 0.48\n",
      "iterration: 412/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 413/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 414/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 415/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 416/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.46\n",
      "iterration: 417/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 418/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 419/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 420/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.46\n",
      "iterration: 421/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 422/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 426/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 427/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration: 428/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.46\n",
      "iterration: 429/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 430/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 431/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 432/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 433/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 434/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.46\n",
      "iterration: 435/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 436/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.49\n",
      "iterration: 437/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 438/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 439/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 443/1700\n",
      "accuracy: 0.76\n",
      "loss: 0.49\n",
      "iterration: 444/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 445/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.48\n",
      "iterration: 446/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 447/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 448/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 449/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 450/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 451/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.46\n",
      "iterration: 452/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 453/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.46\n",
      "iterration: 454/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 455/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 456/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 460/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 461/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 462/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.41\n",
      "iterration: 463/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.45\n",
      "iterration: 464/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 465/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 466/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 467/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 468/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 469/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.47\n",
      "iterration: 470/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 471/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.47\n",
      "iterration: 472/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 473/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 477/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 478/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 479/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 480/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.47\n",
      "iterration: 481/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 482/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 483/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 484/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 485/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 486/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 487/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 488/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 489/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 490/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.48\n",
      "iterration: 494/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 495/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 496/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 497/1700\n",
      "accuracy: 0.78\n",
      "loss: 0.46\n",
      "iterration: 498/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 499/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.43\n",
      "iterration: 500/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 501/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 502/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 503/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 504/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 505/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 506/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.47\n",
      "iterration: 507/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 511/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 512/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 513/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 514/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 515/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 516/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 517/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 518/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 519/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.41\n",
      "iterration: 520/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 521/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 522/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 523/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 524/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 528/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 529/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 530/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.46\n",
      "iterration: 531/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 532/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 533/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 534/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 535/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 536/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 537/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 538/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 539/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 540/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 541/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 545/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 546/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.43\n",
      "iterration: 547/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 548/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 549/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 550/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 551/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 552/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 553/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 554/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.43\n",
      "iterration: 555/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.43\n",
      "iterration: 556/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 557/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 558/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 562/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 563/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 564/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.45\n",
      "iterration: 565/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 566/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 567/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.41\n",
      "iterration: 568/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 569/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 570/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 571/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 572/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 573/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 574/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 575/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.41\n",
      "iterration: 579/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.42\n",
      "iterration: 580/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 581/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 582/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 583/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 584/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 585/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 586/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 587/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.43\n",
      "iterration: 588/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 589/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.43\n",
      "iterration: 590/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 591/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.43\n",
      "iterration: 592/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 596/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 597/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 598/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 599/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 600/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 601/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 602/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 603/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 604/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 605/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 606/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.44\n",
      "iterration: 607/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 608/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 609/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.42\n",
      "iterration: 613/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 614/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 615/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.41\n",
      "iterration: 616/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 617/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 618/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 619/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 620/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 621/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 622/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 623/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 624/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 625/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 626/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.43\n",
      "iterration: 630/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 631/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 632/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 633/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 634/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.40\n",
      "iterration: 635/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 636/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 637/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 638/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 639/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration: 640/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.44\n",
      "iterration: 641/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 642/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 643/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.46\n",
      "iterration: 647/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.44\n",
      "iterration: 648/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.45\n",
      "iterration: 649/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 650/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 651/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 652/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.44\n",
      "iterration: 653/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.41\n",
      "iterration: 654/1700\n",
      "accuracy: 0.79\n",
      "loss: 0.43\n",
      "iterration: 655/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.41\n",
      "iterration: 656/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 657/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 658/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 659/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.41\n",
      "iterration: 660/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 664/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 665/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 666/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 667/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 668/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 669/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 670/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 671/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 672/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 673/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 674/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 675/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.43\n",
      "iterration: 676/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 677/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 681/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 682/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 683/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 684/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 685/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 686/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 687/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 688/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 689/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.41\n",
      "iterration: 690/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 691/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 692/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 693/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.40\n",
      "iterration: 694/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.41\n",
      "iterration: 698/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 699/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 700/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 701/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 702/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 703/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 704/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 705/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 706/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 707/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 708/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 709/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 710/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 711/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 715/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 716/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 717/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.41\n",
      "iterration: 718/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 719/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 720/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 721/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 722/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 723/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.43\n",
      "iterration: 724/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 725/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 726/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 727/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 728/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 732/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 733/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.41\n",
      "iterration: 734/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 735/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.41\n",
      "iterration: 736/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 737/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 738/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 739/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 740/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 741/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 742/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 743/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 744/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 745/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.43\n",
      "iterration: 749/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 750/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 751/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 752/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 753/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 754/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 755/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 756/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 757/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 758/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 759/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 760/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 761/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 762/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 766/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 767/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 768/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 769/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 770/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 771/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 772/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 773/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 774/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.40\n",
      "iterration: 775/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 776/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 777/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 778/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.41\n",
      "iterration: 779/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 783/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.41\n",
      "iterration: 784/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 785/1700\n",
      "accuracy: 0.80\n",
      "loss: 0.42\n",
      "iterration: 786/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 787/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 788/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.41\n",
      "iterration: 789/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 790/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 791/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 792/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 793/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 794/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 795/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 796/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 800/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 801/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 802/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 803/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 804/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 805/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.41\n",
      "iterration: 806/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 807/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 808/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 809/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 810/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 811/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 812/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 813/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 817/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 818/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 819/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 820/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 821/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.41\n",
      "iterration: 822/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 823/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 824/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 825/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 826/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 827/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 828/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 829/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 830/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 834/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 835/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 836/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 837/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 838/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 839/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 840/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 841/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 842/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 843/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 844/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 845/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 846/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 847/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 851/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 852/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 853/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration: 854/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 855/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 856/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 857/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 858/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.42\n",
      "iterration: 859/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 860/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 861/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 862/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 863/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 864/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 868/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 869/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 870/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 871/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 872/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 873/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 874/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 875/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 876/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 877/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 878/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 879/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 880/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 881/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 885/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 886/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 887/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 888/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 889/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 890/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 891/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 892/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 893/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.38\n",
      "iterration: 894/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 895/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 896/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 897/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 898/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 902/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 903/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 904/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 905/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 906/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 907/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 908/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 909/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 910/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 911/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 912/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 913/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 914/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 915/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.41\n",
      "iterration: 919/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 920/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 921/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 922/1700\n",
      "accuracy: 0.81\n",
      "loss: 0.42\n",
      "iterration: 923/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 924/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 925/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 926/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 927/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.37\n",
      "iterration: 928/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 929/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 930/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 931/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 932/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 936/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 937/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 938/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 939/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 940/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 941/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 942/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 943/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 944/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 945/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 946/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 947/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 948/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 949/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 953/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 954/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 955/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 956/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 957/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 958/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 959/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 960/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 961/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 962/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 963/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 964/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 965/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 966/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 970/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 971/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 972/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 973/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 974/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 975/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 976/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 977/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 978/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 979/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 980/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 981/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 982/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.40\n",
      "iterration: 983/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 987/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 988/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 989/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 990/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 991/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 992/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 993/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 994/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 995/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 996/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 997/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 998/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 999/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1000/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1004/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1005/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1006/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1007/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1008/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1009/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 1010/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1011/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1012/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.38\n",
      "iterration: 1013/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1014/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 1015/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 1016/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1017/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 1021/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1022/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1023/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.39\n",
      "iterration: 1024/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1025/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1026/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 1027/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1028/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1029/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1030/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1031/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 1032/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1033/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1034/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1038/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1039/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1040/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1041/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1042/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1043/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1044/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1045/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1046/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1047/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1048/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1049/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1050/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1051/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1055/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1056/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1057/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1058/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1059/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1060/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 1061/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1062/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1063/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration: 1064/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1065/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1066/1700\n",
      "accuracy: 0.82\n",
      "loss: 0.40\n",
      "iterration: 1067/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1068/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1072/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1073/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1074/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1075/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1076/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 1077/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1078/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1079/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 1080/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1081/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1082/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1083/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1084/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1085/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1089/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1090/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1091/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1092/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1093/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1094/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1095/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1096/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1097/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1098/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1099/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1100/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 1101/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1102/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1106/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 1107/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1108/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1109/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1110/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1111/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1112/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1113/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1114/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1115/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1116/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1117/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1118/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1119/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.36\n",
      "iterration: 1123/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1124/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1125/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1126/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1127/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1128/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1129/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1130/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1131/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1132/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1133/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1134/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1135/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1136/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1140/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1141/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 1142/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1143/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1144/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1145/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1146/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1147/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1148/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1149/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1150/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1151/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1152/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1153/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1157/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1158/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1159/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1160/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1161/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1162/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1163/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1164/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1165/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1166/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1167/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1168/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1169/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1170/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1174/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1175/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1176/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1177/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1178/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1179/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1180/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1181/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1182/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1183/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1184/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1185/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1186/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1187/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.39\n",
      "iterration: 1191/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1192/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1193/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1194/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1195/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1196/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1197/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1198/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1199/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1200/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1201/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.39\n",
      "iterration: 1202/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1203/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.36\n",
      "iterration: 1204/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1208/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1209/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1210/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1211/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1212/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1213/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.38\n",
      "iterration: 1214/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1215/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1216/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1217/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1218/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1219/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1220/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1221/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1225/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1226/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1227/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1228/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1229/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1230/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1231/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1232/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1233/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1234/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1235/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1236/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1237/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1238/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1242/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1243/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1244/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1245/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1246/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1247/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1248/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1249/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1250/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1251/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1252/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1253/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1254/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1255/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.36\n",
      "iterration: 1259/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1260/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1261/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1262/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1263/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1264/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1265/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1266/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1267/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1268/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1269/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1270/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration: 1271/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1272/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1276/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1277/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1278/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1279/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1280/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1281/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1282/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1283/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1284/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1285/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1286/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1287/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1288/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1289/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1293/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1294/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1295/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1296/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1297/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1298/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1299/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1300/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.38\n",
      "iterration: 1301/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1302/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1303/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1304/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1305/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1306/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1310/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1311/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1312/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1313/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1314/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1315/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1316/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1317/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1318/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1319/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1320/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1321/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1322/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1323/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1327/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1328/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1329/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1330/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1331/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1332/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1333/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1334/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1335/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1336/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1337/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1338/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1339/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1340/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1344/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1345/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1346/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1347/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1348/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1349/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1350/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1351/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1352/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1353/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1354/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1355/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1356/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1357/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1361/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1362/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1363/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1364/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1365/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1366/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1367/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1368/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.33\n",
      "iterration: 1369/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1370/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1371/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1372/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1373/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1374/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1378/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1379/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1380/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1381/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1382/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1383/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1384/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1385/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1386/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1387/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1388/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1389/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1390/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1391/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1395/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1396/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1397/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1398/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1399/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1400/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1401/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1402/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1403/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1404/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1405/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1406/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1407/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1408/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1412/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1413/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1414/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1415/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1416/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1417/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1418/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1419/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1420/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1421/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1422/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1423/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1424/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1425/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1429/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1430/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1431/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1432/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1433/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1434/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1435/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1436/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1437/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1438/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1439/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1440/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1441/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1442/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.32\n",
      "iterration: 1446/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1447/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1448/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1449/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1450/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1451/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1452/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1453/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1454/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1455/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1456/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1457/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1458/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1459/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1463/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1464/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.36\n",
      "iterration: 1465/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1466/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.34\n",
      "iterration: 1467/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1468/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1469/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1470/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1471/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1472/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1473/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1474/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1475/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1476/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1480/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration: 1481/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1482/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1483/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1484/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.33\n",
      "iterration: 1485/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1486/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1487/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.33\n",
      "iterration: 1488/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1489/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.35\n",
      "iterration: 1490/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1491/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1492/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1493/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1497/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1498/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1499/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1500/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1501/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1502/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.37\n",
      "iterration: 1503/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1504/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1505/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1506/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.34\n",
      "iterration: 1507/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1508/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1509/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.30\n",
      "iterration: 1510/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1514/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1515/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1516/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1517/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1518/1700\n",
      "accuracy: 0.83\n",
      "loss: 0.37\n",
      "iterration: 1519/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.33\n",
      "iterration: 1520/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.37\n",
      "iterration: 1521/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1522/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1523/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.34\n",
      "iterration: 1524/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.36\n",
      "iterration: 1525/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1526/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1527/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1531/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1532/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1533/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1534/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1535/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1536/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1537/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1538/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1539/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1540/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1541/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1542/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1543/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1544/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1548/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1549/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.33\n",
      "iterration: 1550/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1551/1700\n",
      "accuracy: 0.88\n",
      "loss: 0.32\n",
      "iterration: 1552/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1553/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1554/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1555/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1556/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1557/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1558/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1559/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1560/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1561/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1565/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1566/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.34\n",
      "iterration: 1567/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1568/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1569/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1570/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1571/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1572/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1573/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1574/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1575/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1576/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.33\n",
      "iterration: 1577/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1578/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1582/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1583/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1584/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1585/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1586/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1587/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1588/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1589/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1590/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1591/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1592/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1593/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1594/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1595/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1599/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1600/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1601/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1602/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1603/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1604/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1605/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1606/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1607/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1608/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1609/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1610/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1611/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1612/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1616/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1617/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.34\n",
      "iterration: 1618/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1619/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1620/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1621/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1622/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1623/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.30\n",
      "iterration: 1624/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1625/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1626/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1627/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1628/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1629/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1633/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1634/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1635/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1636/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1637/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1638/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1639/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1640/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1641/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.35\n",
      "iterration: 1642/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.33\n",
      "iterration: 1643/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.35\n",
      "iterration: 1644/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1645/1700\n",
      "accuracy: 0.84\n",
      "loss: 0.36\n",
      "iterration: 1646/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1650/1700\n",
      "accuracy: 0.88\n",
      "loss: 0.30\n",
      "iterration: 1651/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1652/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1653/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1654/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1655/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1656/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1657/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1658/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1659/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1660/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1661/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1662/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1663/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1667/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1668/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1669/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1670/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1671/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1672/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1673/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1674/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1675/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1676/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1677/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1678/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1679/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.33\n",
      "iterration: 1680/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1684/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.30\n",
      "iterration: 1685/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.32\n",
      "iterration: 1686/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.34\n",
      "iterration: 1687/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration: 1688/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1689/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1690/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1691/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.34\n",
      "iterration: 1692/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n",
      "iterration: 1693/1700\n",
      "accuracy: 0.85\n",
      "loss: 0.36\n",
      "iterration: 1694/1700\n",
      "accuracy: 0.87\n",
      "loss: 0.31\n",
      "iterration: 1695/1700\n",
      "accuracy: 0.88\n",
      "loss: 0.31\n",
      "iterration: 1696/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.33\n",
      "iterration: 1697/1700\n",
      "accuracy: 0.86\n",
      "loss: 0.32\n"
     ]
    }
   ],
   "source": [
    "list_train_loss = []\n",
    "list_train_acc = []\n",
    "for epoch in range(epochs):\n",
    "    #def __init__(self, data, sent_size, corpus, dtype=\"\"):\n",
    "    dtrain_set = DP.CommentDataset(dataset=train_dataset, \n",
    "                                   sent_size=sent_size, \n",
    "                                   corpus=corpus, \n",
    "                                   dtype=\"train\")\n",
    "    train_loader = DataLoader(dtrain_set,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             num_workers=4)\n",
    "    for i, train_data in enumerate(train_loader, 1):\n",
    "        data, labels = train_data\n",
    "        if len(data) != 1: labels = torch.squeeze(labels)\n",
    "        \n",
    "        if use_gpu:\n",
    "            data = Variable(data.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else: data = Variable(data)\n",
    "    \n",
    "        model.zero_grad()\n",
    "        model.batch_size = len(labels)\n",
    "        model.hidden = model.init_hidden()\n",
    "        output = model(data.t())\n",
    "\n",
    "        loss = loss_fn(output, Variable(labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        train_acc = ((pred == labels).sum()).item()\n",
    "        total = len(labels)\n",
    "        acc = (train_acc / total)\n",
    "        train_loss = loss.data.item()\n",
    "        list_train_acc.append(acc)\n",
    "        list_train_loss.append(train_loss)\n",
    "        print(\"iterration: \"+str(epoch*17+i)+'/'+str(epochs*17))\n",
    "        print(\"accuracy: %.2f\" % round(acc,2))\n",
    "        print(\"loss: %.2f\" % round(train_loss, 2))\n",
    "    \n",
    "file_train_acc = open(\"data/plot/train_acc.pickle\", 'wb')\n",
    "pickle.dump(list_train_acc, file_train_acc)\n",
    "file_train_loss = open(\"data/plot/train_loss.pickle\", 'wb')\n",
    "pickle.dump(list_train_loss, file_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fn = []\n",
    "list_fp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = tn = fp = fn = 0\n",
    "#def __init__(self, data, sent_size, corpus, dtype=\"\"):\n",
    "dtest_set = DP.CommentDataset(dataset=test_dataset,\n",
    "                             sent_size=sent_size,\n",
    "                             corpus=corpus,\n",
    "                             dtype=\"test\")\n",
    "\n",
    "test_loader = DataLoader(dtest_set,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=4)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        data, labels = test_data\n",
    "        labels = torch.squeeze(labels)\n",
    "        \n",
    "        if use_gpu:\n",
    "            data = Variable(data.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else: data = Variable(data)\n",
    "        \n",
    "        model.batch_size = len(labels)\n",
    "        model.hidden = model.init_hidden()\n",
    "        output = model(data.t())\n",
    "\n",
    "        \n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        for i in range(len(pred)):\n",
    "            if labels[i].item() == 1 and pred[i].item() == 1: tp+=1\n",
    "            elif labels[i].item() == 0 and pred[i].item() == 1:\n",
    "                list_fp.append(data[i])\n",
    "                fp+=1\n",
    "            elif labels[i].item() == 1 and pred[i].item() == 0:\n",
    "                list_fn.append(data[i])\n",
    "                fn+=1\n",
    "            elif labels[i].item() == 0 and pred[i].item() == 0: tn+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(list_fn))\n",
    "print(len(list_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for l in list_fp:\n",
    "    temp = []\n",
    "    for i in range(len(l)):\n",
    "        if l[i] == 0: break\n",
    "        temp.append(corpus.dictionary.words[l[i]])\n",
    "    res.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kejelasan']\n",
      "['app']\n"
     ]
    }
   ],
   "source": [
    "for r in res: print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([  207,   735,   329,   347,  4182,   933,  3899,  8904,   329,   573,\n",
       "           329, 10614,   979,     0,     0]),\n",
       " tensor([ 339, 2258,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0]),\n",
       " tensor([13649,  1167,  9305,  1114,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]),\n",
       " tensor([7387,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0]),\n",
       " tensor([ 265,  347, 3430,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0]),\n",
       " tensor([93,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " tensor([ 6377,   302, 14586,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]),\n",
       " tensor([ 148, 3060,   61,  205, 4290,  373,  342,  381, 7742,  529, 6031,  373,\n",
       "         9935,  185,  305]),\n",
       " tensor([ 1176, 14586,   522,  7831,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]),\n",
       " tensor([527, 307,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0]),\n",
       " tensor([6099,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0]),\n",
       " tensor([ 736, 1896,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0])]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive:  56\n",
      "false positive:  2\n",
      "false negative:  12\n",
      "true negative:  11\n",
      "accuracy: 0.83\n",
      "precision: 0.97\n",
      "recall: 0.82\n",
      "f1 score: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive: \", tp)\n",
    "print(\"false positive: \", fp)\n",
    "print(\"false negative: \", fn)\n",
    "print(\"true negative: \", tn)\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + fn + tn)\n",
    "precission = tp / (tp + fp)\n",
    "recall = tp / (tp + fn) \n",
    "f1_score = 2 * (precission * recall) / (precission + recall)\n",
    "print(\"accuracy: %.2f\" % round(acc, 2))\n",
    "print(\"precision: %.2f\" % round(precission, 2))\n",
    "print(\"recall: %.2f\" % round(recall, 2))\n",
    "print(\"f1 score: %.2f\" % round(f1_score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461538461538461"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.PlotFigure as PF\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "file_acc = open(\"data/plot/train_acc.pickle\", 'rb')\n",
    "list_train_acc = pickle.load(file_acc)\n",
    "file_loss = open(\"data/plot/train_loss.pickle\", 'rb')\n",
    "list_train_loss = pickle.load(file_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PF.plot_acc_loss(list_train_acc, list_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE4hJREFUeJzt3Xu0ZnV93/H3RwYCCHIJByTcRmHAIq2osxBr2jQKxEsqJEW8BSYtSNOoNbQsJepymYQYYmJpamorXspoBbkEBF0hCIhRQJGDgNwiIAWFhTBSUEFjA3z7x/4d83g8Z859zsxv3q+1nnV++7d/z97fvec8n7Of33OZVBWSpE3f05a7AEnS4jDQJakTBrokdcJAl6ROGOiS1AkDXZI6YaBro5dkZZJKsqItX5JkzTy2s3eSx5JssfhVzl+SM5Ocutx1aNNnoGtRJLknyY9bYD7YQmq7pdhXVb2iqtbOsqbDRu737ararqqeXKxakhya5PGpjjXJDUneslj7kmZioGsx/euq2g54AbAaePfkARl083tXVV8F7gOOHu1PchBwIHD2ctSlzVM3DyxtPKrqfuAS4CCAJF9M8sdJrgZ+BDw7yQ5JPpbkgST3Jzl1YiokyRZJ/jzJ95LcDbxqdPtteyeMLL8pye1JfpjktiQvSPJJYG/gs+1Zw9tHp26SvDbJ+KTtnpTk4tb+hVbDt9szjv+ZZJtpDnktcNykvuOAv66qh9v2zkvy3STfT/KlJM+dakNJfjvJVZP6Ksl+86hLmxkDXYsuyV7AK4EbRrqPBU4EtgfuBc4EngD2A54PHAFMhPSbgF9v/auZdPU7aV+vAd7LEKDPAF4NPFxVxwLfpj1rqKr3T7rrZ4EDkqwa6XsDcFZrnwbsDxzcatwDeM80ZXwS+JftuGnPQN7AEPQTLgFWAbsCXwc+Nd0xzWAudWlzU1XevC34BtwDPAY8yhDYHwK2aeu+CPzhyNjdgJ9MrG99rweubO0vAL8zsu4IoIAVI9s7obUvBd62npoOG1leOWk7/xt4T2uvAn4IbAsEeBzYd+S+Lwb+z3qO/3Lgna19OLAO2HKasTu2OnZoy2cCp7b2bwNXTRpfDOE957q8bV63FXPMf2l9jqqqy6dZ952R9j7AlsADSSb6njYy5pcmjb93PfvcC/jW3EsFhqvxDwB/yHBF/Zmq+lGSXRmC/fqR+gKs790xa4F3Au9jeDby6ar6BximkIA/Bl4DjAFPtfvsAnx/DvWOzaMubUYMdG0oo1/r+R2GK/RdquqJKcY+wBDUE/Zez3a/A+w7i31O5TJgLMnBDM8QTmr93wN+DDy3htcDZuMC4ENJfhX4TeBfjax7A3AkcBjDs4YdgEcYwniyxxlCG4AkzxxZN5+6tBlxDl0bXFU9AHwe+ECSZyR5WpJ9k/xKG3Iu8B+T7JlkJ+CU9Wzuo8DJSV7Y3kGzX5J92roHgWevp45/AM4D/gzYmSHgqaqngI8Ap7erdZLskeTX1rOtx4Hzgf8F3FtVoy+4bs/wB+xhhrB+33qO5ybguUkOTrI1w+sDE/uYc13avBjoWi7HAVsBtzFcrZ4P7N7WfYRhbvwmhhcQL5huI1V1HsN0xlkMc+CfYQhngD8B3p3k0SQnT7OJsxiunM+b9GzhHcBdwFeT/IBhjvyAGY5pLcN00icm9X+CYdro/na8X13P8dzBMAV0OXAncNWkIfOpS5uJVPkfXEhSD7xCl6ROGOiS1AkDXZI6YaBLUic26PvQd9lll1q5cuWG3KUkbfKuv/7671XV2EzjNmigr1y5kvHx8ZkHSpJ+Ksn6Pi39U065SFInDHRJ6oSBLkmdMNAlqRMGuiR1wkCXpE4Y6JLUCQNdkjphoEtSJzaZ/4Lu9MvuWO4SltVJh++/3CVI2sh5hS5JnTDQJakTBrokdcJAl6ROGOiS1AkDXZI6YaBLUicMdEnqhIEuSZ0w0CWpEwa6JHXCQJekThjoktQJA12SOmGgS1InDHRJ6oSBLkmdMNAlqROz+i/oktwD/BB4EniiqlYn2Rk4B1gJ3AMcU1WPLE2ZkqSZzOUK/Ver6uCqWt2WTwGuqKpVwBVtWZK0TBYy5XIksLa11wJHLbwcSdJ8zTbQC/h8kuuTnNj6dquqB1r7u8BuU90xyYlJxpOMr1u3boHlSpKmM6s5dOCXq+r+JLsClyX5u9GVVVVJaqo7VtUZwBkAq1evnnKMJGnhZnWFXlX3t58PARcChwAPJtkdoP18aKmKlCTNbMZAT/L0JNtPtIEjgFuAi4E1bdga4KKlKlKSNLPZTLnsBlyYZGL8WVX1N0muA85NcjxwL3DM0pUpSZrJjIFeVXcDz5ui/2HgZUtRlCRp7vykqCR1wkCXpE4Y6JLUCQNdkjphoEtSJwx0SeqEgS5JnTDQJakTBrokdcJAl6ROGOiS1AkDXZI6YaBLUicMdEnqhIEuSZ0w0CWpEwa6JHXCQJekThjoktQJA12SOmGgS1InDHRJ6oSBLkmdMNAlqRMGuiR1wkCXpE4Y6JLUCQNdkjox60BPskWSG5J8ri0/K8m1Se5Kck6SrZauTEnSTOZyhf424PaR5T8FTq+q/YBHgOMXszBJ0tzMKtCT7Am8CvhoWw7wUuD8NmQtcNRSFChJmp3ZXqH/V+DtwFNt+ReBR6vqibZ8H7DHVHdMcmKS8STj69atW1CxkqTpzRjoSX4deKiqrp/PDqrqjKpaXVWrx8bG5rMJSdIsrJjFmJcAr07ySmBr4BnAXwA7JlnRrtL3BO5fujIlSTOZ8Qq9qn6/qvasqpXA64AvVNUbgSuBo9uwNcBFS1alJGlGC3kf+juA/5TkLoY59Y8tTkmSpPmYzZTLT1XVF4EvtvbdwCGLX5IkaT78pKgkdcJAl6ROGOiS1AkDXZI6YaBLUicMdEnqhIEuSZ0w0CWpEwa6JHXCQJekThjoktQJA12SOmGgS1InDHRJ6oSBLkmdMNAlqRMGuiR1wkCXpE4Y6JLUCQNdkjphoEtSJwx0SeqEgS5JnTDQJakTBrokdcJAl6ROGOiS1AkDXZI6MWOgJ9k6ydeS3JTk1iR/0PqfleTaJHclOSfJVktfriRpOrO5Qv8J8NKqeh5wMPDyJIcCfwqcXlX7AY8Axy9dmZKkmcwY6DV4rC1u2W4FvBQ4v/WvBY5akgolSbMyqzn0JFskuRF4CLgM+BbwaFU90YbcB+wxzX1PTDKeZHzdunWLUbMkaQqzCvSqerKqDgb2BA4BnjPbHVTVGVW1uqpWj42NzbNMSdJM5vQul6p6FLgSeDGwY5IVbdWewP2LXJskaQ5m8y6XsSQ7tvY2wOHA7QzBfnQbtga4aKmKlCTNbMXMQ9gdWJtkC4Y/AOdW1eeS3AZ8OsmpwA3Ax5awTknSDGYM9Kr6BvD8KfrvZphPlyRtBPykqCR1wkCXpE4Y6JLUCQNdkjphoEtSJwx0SeqEgS5JnTDQJakTBrokdcJAl6ROGOiS1AkDXZI6YaBLUicMdEnqhIEuSZ0w0CWpEwa6JHXCQJekThjoktQJA12SOmGgS1InDHRJ6oSBLkmdMNAlqRMGuiR1wkCXpE4Y6JLUCQNdkjoxY6An2SvJlUluS3Jrkre1/p2TXJbkzvZzp6UvV5I0ndlcoT8B/OeqOhA4FHhzkgOBU4ArqmoVcEVbliQtkxkDvaoeqKqvt/YPgduBPYAjgbVt2FrgqKUqUpI0sznNoSdZCTwfuBbYraoeaKu+C+w2zX1OTDKeZHzdunULKFWStD6zDvQk2wF/BfxeVf1gdF1VFVBT3a+qzqiq1VW1emxsbEHFSpKmN6tAT7IlQ5h/qqouaN0PJtm9rd8deGhpSpQkzcZs3uUS4GPA7VX1X0ZWXQysae01wEWLX54kabZWzGLMS4BjgZuT3Nj63gmcBpyb5HjgXuCYpSlRkjQbMwZ6VV0FZJrVL1vcciRJ8+UnRSWpEwa6JHXCQJekThjoktQJA12SOmGgS1InDHRJ6oSBLkmdMNAlqRMGuiR1wkCXpE4Y6JLUCQNdkjphoEtSJwx0SeqEgS5JnTDQJakTBrokdcJAl6ROGOiS1AkDXZI6YaBLUicMdEnqxIrlLkDaFJx+2R3LXcKyOunw/Ze7BM2CV+iS1AkDXZI6YaBLUiecQ5e05HwNYsO8BjHjFXqSjyd5KMktI307J7ksyZ3t505LW6YkaSazmXI5E3j5pL5TgCuqahVwRVuWJC2jGQO9qr4E/N9J3UcCa1t7LXDUItclSZqj+b4oultVPdDa3wV2m25gkhOTjCcZX7du3Tx3J0mayYLf5VJVBdR61p9RVauravXY2NhCdydJmsZ8A/3BJLsDtJ8PLV5JkqT5mG+gXwysae01wEWLU44kab5m87bFs4GvAAckuS/J8cBpwOFJ7gQOa8uSpGU04weLqur106x62SLXIklaAD/6L0mdMNAlqRMGuiR1wkCXpE4Y6JLUCQNdkjphoEtSJwx0SeqEgS5JnTDQJakTBrokdcJAl6ROGOiS1AkDXZI6YaBLUicMdEnqhIEuSZ0w0CWpEwa6JHXCQJekThjoktQJA12SOmGgS1InVix3AdowTr/sjuUuYVmddPj+y12CtOS8QpekThjoktQJA12SOmGgS1InFhToSV6e5JtJ7kpyymIVJUmau3kHepItgP8OvAI4EHh9kgMXqzBJ0tws5Ar9EOCuqrq7qv4f8GngyMUpS5I0V6mq+d0xORp4eVWd0JaPBV5UVW+ZNO5E4MS2eADwzfmXu6x2Ab633EVswjx/C+P5W5hN/fztU1VjMw1a8g8WVdUZwBlLvZ+llmS8qlYvdx2bKs/fwnj+FmZzOX8LmXK5H9hrZHnP1idJWgYLCfTrgFVJnpVkK+B1wMWLU5Ykaa7mPeVSVU8keQtwKbAF8PGqunXRKtv4bPLTRsvM87cwnr+F2SzO37xfFJUkbVz8pKgkdcJAl6ROdPd96El+EbiiLT4TeBJY15YPaR+C0jSSPAncPNJ1VFXdM83YlcDnquqgpa9s4+e5WzgfvwvTXaBX1cPAwQBJ3gs8VlV/PjomSRheP3hqw1e40ftxVR283EVsojx3C+Tjd2E2mymXJPsluS3Jp4Bbgb2SPDqy/nVJPtrauyW5IMl4kq8lOXSK7Z2Q5MIkf5vkziTvHln39iS3tNtbW9/2SS5JclPrP3rpj3pxJFmZ5MtJvt5u/3yKMc9t5+rGJN9Isqr1/9ZI/4fbdwBNvu89Sd6f5OY2dr+R/X6hbe+KJHu3/te0c3hTki8t9fEvxAY6d3/Qtn1zkue0/qcn+Xi7/w1Jjmz92yY5tz0WLkxybZKN/gM3S/T4PT/Jpe3x+ycj616R5CvtnJ6T5Omt/9UZvozw+iQfTPKZpT/yOaqqbm/Ae4GTW3s/4ClgdVteATw6MvZ1wEdb+xzg0NZeCdwyxbZPYPgg1U7A04HbGK4sXgTcBGwDbA/cDvxT4LXA/xi5/w7LfX6mOWdPAje224Wtb1tg69ZeBYxPPjfAB4E3tvZW7fj/CfBZYMvW/yHguCn2eQ/wrtY+jmEqgnbfNa3974DPtPbNwB6tveNyn7ON4Ny9tbV/d+R3+H3Ab02cI+CO9nt6MvDh1n8Q8MTEY2Jju7H0j987gWe08/0d4JeAXYG/BbZt494FvLP9O94H7AMEOG/i93FjunU35TKDb1XV+CzGHQYcMDyzA2CnJNtU1Y8njbu0qh4BaH+tfxn4BeCvJsa2/n8BXAmcluQ04LNVdfXCD2dJTDVtsCXwl0kOZgitqf6Dzq8A70qyJ3BBVd2Z5GXAC4Hr2rncBnhomv2ePfLz9NZ+MfCbrf1J4P2tfTVwZpJzgQvmcnBLbLnO3cQ5uJ5/PF9HAK9OcnJb3hrYm+F39C8AquqWJN+Y4zEup8V+/F5eVT8ASPJ3DOfnmQzfHntNu/9WwFWt75tVdW8bfzbDxcdGZXML9MdH2k8x/KWdsPVIO8zuBZjJb+Kf9k39VXV7e2r7SoZgv6Sq3jeLmjcGJwEPAs9jmKb7+8kDquqsJNcCrwL+Osm/ZziPa6vq92exj5qm/fMDq34nyYvavq5P8sIa5l43Rhvi3P2k/XySf3xMB/g3VfUzX4Y3EnKbosV+/P5kpD1x7gL8TVUdOzpwU5iWgs1oDn2yGl5QeSTJqiRPA35jZPXlwJsnFtrV1VSOSLJjkm0Zvjr4auDLwG8k2SbJdq3/y0n2YHiB55PAB4AXLP5RLZkdgAfaOTuW4ZPBPyPJs4G7q+q/ARcB/4zh3QpHJ9m1jdk5yT7T7OO1Iz+/0trXMDyVBngjw7klyb5VdW1VvYfhHRCj3ym0sdkQ524qlwJvTUvwJM9v/VcDx7S+AxmmAzc5i/T4nco1wK+0f5OJ1yJWMUypHpBkr3ZOX7u+jSyXzTbQm3cw/OJfwzA/NuHNwEvaC1S3AW+a5v7XMTwAbwLOrqobq+prDNMG1wFfZZg3v5nhCu26JDcyzMltKlfnMMzfrklyE/AcfvZKacIxwC3t+A4CPlFVtwHvBj7fntpfBuw+zT52amPexnBVC/BW4N+2/mPbOoA/ay8A3sLwb3fTgo9w6WyIczeVP2KY7vlGklvb8kQ9Y+33+lSGFxi/P/fD2igs9PH7c6rqQeB44Jz2b3YNsH9V/Qh4C8Mfi3HgUTbC8+ZH/+cpyQnAQVX1e8tdy6YuyT0ML3Ztyt9XvUlo75TZsqr+Psm+DAF1wCymJzZ7SbarqsfaFfqHgZur6oPLXdeozW0OXdrcbQtcmWRLhvni3zXMZ+0/JHkjwxsfxoGPLHM9P8crdEnqxOY+hy5J3TDQJakTBrokdcJAl6ROGOiS1In/D91wxGLRszMZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PF.plot_metric(tp, fp, fn, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"data/model/lstm_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.review_checker as review_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "sent = \"aplikasi nggak guna\"\n",
    "review_checker.check(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'star': 5,\n",
       " 'comment': 'the best services in price tiketing compare with other company'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goog',\n",
       " 'thanks',\n",
       " 'traveloka',\n",
       " 'tsb',\n",
       " 'udah',\n",
       " 'update',\n",
       " 'no',\n",
       " 'bug',\n",
       " 'the',\n",
       " 'best']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dictionary.words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2060, -0.4012,  0.7832,  0.2629, -0.1298, -0.2708, -1.1152,  0.0543,\n",
       "          0.3435, -0.9986, -0.4232, -0.8043,  1.7083,  0.4477,  0.5948]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_embeddings(torch.tensor([1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-comment",
   "language": "python",
   "name": "semantic-comment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
